# ğŸ¤– LangChat â€” Your AI Chat Companion  
*(Powered by LangGraph + FastAPI + Streamlit)*

Hey there! ğŸ‘‹  
Welcome to **LangChat**, where your chatbot isn't just smartâ€”itâ€™s smooth, structured, and seriously cool ğŸ˜.

This repo brings you a modular AI chatbot with **LangGraph agents**, a snappy **FastAPI** backend, and a clean **Streamlit** UI. Think of it as brains + beauty + speed = ğŸ’¯

---

## ğŸ§  Architecture at a Glance

LangChat works in **3 neat phases**:

### ğŸ”¹ Phase 1 â€” Brain Power (LLM Core)
- Uses **LangGraph agents** to handle conversation logic.
- Works with **Groq**, **OpenAI**, **Tavily**, **Meta**, and more.
- Can switch tools/models based on context. Smart, huh?

### ğŸ”¹ Phase 2 â€” FastAPI Backend
- Handles incoming API requests and outgoing responses.
- Validates data with **Pydantic**.
- Runs on **Uvicorn** for that blazing-fast speed.

### ğŸ”¹ Phase 3 â€” Streamlit UI
- Clean, simple interface for user interaction.
- Super easy to use. Just type and talk!

---

## âš™ï¸ Tech Stack

| Layer       | Tools Used                              |
|-------------|------------------------------------------|
| ğŸ§  LLM Core | LangGraph, OpenAI, Groq, Tavily, Meta   |
| ğŸ”Œ Backend  | FastAPI, Pydantic, Uvicorn              |
| ğŸ¨ Frontend | Streamlit                               |

---

## ğŸš€ How to Run This Locally

Hereâ€™s the 5-step magic spell to launch LangChat:

```bash
# 1. Clone the repo
git clone https://github.com/Aditi-Singh-15/LangChat.git

# 2. (Optional) Create a virtual environment
python -m venv env
source env/bin/activate  # For Windows: env\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start the backend server
uvicorn backend.main:app --reload

# 5. Run the Streamlit frontend
streamlit run frontend.py

```
## ğŸŒŸ Features

- ğŸ§  **Dynamic model selection** (OpenAI / Groq)  
- ğŸ¤– **LangGraph Agent + Tool chaining**  
- ğŸ”Œ **Modular FastAPI backend**  
- ğŸ¨ **Beautiful Streamlit frontend**  
- ğŸ› ï¸ **Tool support** (Tavily, Meta, etc.)

---

## ğŸ§© Whatâ€™s Next?

- [ ] Add memory to retain chat context  
- [ ] Integrate vector store + RAG  
- [ ] Add voice interaction (because why not?)  
- [ ] Cloud deployment + CI/CD (Docker incoming!)

---

## ğŸ™Œ Want to Contribute?

Pull requests are welcome!  
Fork the repo, add your magic âœ¨, and send that PR. Letâ€™s build together.

